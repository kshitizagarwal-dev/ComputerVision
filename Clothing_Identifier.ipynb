{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clothing-Identifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5pq5HCDngaNA3eoFos8zM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kshitizagarwal-dev/ComputerVision/blob/main/Clothing_Identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puYQ2wr9rpc-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6U4lGAkr89Y"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BpRtUUEr9SA",
        "outputId": "0edb3756-31f8-4451-fa30-f75646c48d44"
      },
      "source": [
        "type(mnist)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "module"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4UAfeg-AwY3"
      },
      "source": [
        "Loading the minist dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6FhG08gr9VH",
        "outputId": "5de3845c-68ee-47a0-e5a3-d3631c470d06"
      },
      "source": [
        "(training_images, training_labels),(test_images, test_labels) = mnist.load_data()\n",
        "print(training_images.shape,'\\t', training_labels.shape)\n",
        "print(test_images.shape,'\\t', test_labels.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) \t (60000,)\n",
            "(10000, 28, 28) \t (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rivpp-AmtMTh",
        "outputId": "f48b5e4d-8d8d-4dc2-bb58-9143ffa84db0"
      },
      "source": [
        "test_images[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   3,   1,   0,   0,   7,   0,  37,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          1,   2,   0,  27,  84,  11,   0,   0,   0,   0,   0,   0, 119,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          1,   0,   0,  88, 143, 110,   0,   0,   0,   0,  22,  93, 106,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          4,   0,  53, 129, 120, 147, 175, 157, 166, 135, 154, 168, 140,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n",
              "          0,  11, 137, 130, 128, 160, 176, 159, 167, 178, 149, 151, 144,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   1,   0,   2,   1,   0,   3,   0,\n",
              "          0, 115, 114, 106, 137, 168, 153, 156, 165, 167, 143, 157, 158,\n",
              "         11,   0],\n",
              "       [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   3,   0,   0,\n",
              "         89, 139,  90,  94, 153, 149, 131, 151, 169, 172, 143, 159, 169,\n",
              "         48,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   2,   4,   1,   0,   0,   0,  98,\n",
              "        136, 110, 109, 110, 162, 135, 144, 149, 159, 167, 144, 158, 169,\n",
              "        119,   0],\n",
              "       [  0,   0,   2,   2,   1,   2,   0,   0,   0,   0,  26, 108, 117,\n",
              "         99, 111, 117, 136, 156, 134, 154, 154, 156, 160, 141, 147, 156,\n",
              "        178,   0],\n",
              "       [  3,   0,   0,   0,   0,   0,   0,  21,  53,  92, 117, 111, 103,\n",
              "        115, 129, 134, 143, 154, 165, 170, 154, 151, 154, 143, 138, 150,\n",
              "        165,  43],\n",
              "       [  0,   0,  23,  54,  65,  76,  85, 118, 128, 123, 111, 113, 118,\n",
              "        127, 125, 139, 133, 136, 160, 140, 155, 161, 144, 155, 172, 161,\n",
              "        189,  62],\n",
              "       [  0,  68,  94,  90, 111, 114, 111, 114, 115, 127, 135, 136, 143,\n",
              "        126, 127, 151, 154, 143, 148, 125, 162, 162, 144, 138, 153, 162,\n",
              "        196,  58],\n",
              "       [ 70, 169, 129, 104,  98, 100,  94,  97,  98, 102, 108, 106, 119,\n",
              "        120, 129, 149, 156, 167, 190, 190, 196, 198, 198, 187, 197, 189,\n",
              "        184,  36],\n",
              "       [ 16, 126, 171, 188, 188, 184, 171, 153, 135, 120, 126, 127, 146,\n",
              "        185, 195, 209, 208, 255, 209, 177, 245, 252, 251, 251, 247, 220,\n",
              "        206,  49],\n",
              "       [  0,   0,   0,  12,  67, 106, 164, 185, 199, 210, 211, 210, 208,\n",
              "        190, 150,  82,   8,   0,   0,   0, 178, 208, 188, 175, 162, 158,\n",
              "        151,  11],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqVZYOKpuq3x",
        "outputId": "dac10aa1-8c72-4899-9c8c-e01358b91342"
      },
      "source": [
        "test_images = test_images/255\n",
        "test_images[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
              "        0.00392157, 0.        , 0.        , 0.02745098, 0.        ,\n",
              "        0.14509804, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00392157, 0.00784314,\n",
              "        0.        , 0.10588235, 0.32941176, 0.04313725, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.46666667, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
              "        0.        , 0.34509804, 0.56078431, 0.43137255, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.08627451, 0.36470588,\n",
              "        0.41568627, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.01568627, 0.        ,\n",
              "        0.20784314, 0.50588235, 0.47058824, 0.57647059, 0.68627451,\n",
              "        0.61568627, 0.65098039, 0.52941176, 0.60392157, 0.65882353,\n",
              "        0.54901961, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00784314, 0.        , 0.04313725,\n",
              "        0.5372549 , 0.50980392, 0.50196078, 0.62745098, 0.69019608,\n",
              "        0.62352941, 0.65490196, 0.69803922, 0.58431373, 0.59215686,\n",
              "        0.56470588, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.00784314, 0.00392157,\n",
              "        0.        , 0.01176471, 0.        , 0.        , 0.45098039,\n",
              "        0.44705882, 0.41568627, 0.5372549 , 0.65882353, 0.6       ,\n",
              "        0.61176471, 0.64705882, 0.65490196, 0.56078431, 0.61568627,\n",
              "        0.61960784, 0.04313725, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.01176471, 0.        , 0.        , 0.34901961, 0.54509804,\n",
              "        0.35294118, 0.36862745, 0.6       , 0.58431373, 0.51372549,\n",
              "        0.59215686, 0.6627451 , 0.6745098 , 0.56078431, 0.62352941,\n",
              "        0.6627451 , 0.18823529, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00784314, 0.01568627, 0.00392157, 0.        ,\n",
              "        0.        , 0.        , 0.38431373, 0.53333333, 0.43137255,\n",
              "        0.42745098, 0.43137255, 0.63529412, 0.52941176, 0.56470588,\n",
              "        0.58431373, 0.62352941, 0.65490196, 0.56470588, 0.61960784,\n",
              "        0.6627451 , 0.46666667, 0.        ],\n",
              "       [0.        , 0.        , 0.00784314, 0.00784314, 0.00392157,\n",
              "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.10196078, 0.42352941, 0.45882353, 0.38823529, 0.43529412,\n",
              "        0.45882353, 0.53333333, 0.61176471, 0.5254902 , 0.60392157,\n",
              "        0.60392157, 0.61176471, 0.62745098, 0.55294118, 0.57647059,\n",
              "        0.61176471, 0.69803922, 0.        ],\n",
              "       [0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.08235294, 0.20784314, 0.36078431,\n",
              "        0.45882353, 0.43529412, 0.40392157, 0.45098039, 0.50588235,\n",
              "        0.5254902 , 0.56078431, 0.60392157, 0.64705882, 0.66666667,\n",
              "        0.60392157, 0.59215686, 0.60392157, 0.56078431, 0.54117647,\n",
              "        0.58823529, 0.64705882, 0.16862745],\n",
              "       [0.        , 0.        , 0.09019608, 0.21176471, 0.25490196,\n",
              "        0.29803922, 0.33333333, 0.4627451 , 0.50196078, 0.48235294,\n",
              "        0.43529412, 0.44313725, 0.4627451 , 0.49803922, 0.49019608,\n",
              "        0.54509804, 0.52156863, 0.53333333, 0.62745098, 0.54901961,\n",
              "        0.60784314, 0.63137255, 0.56470588, 0.60784314, 0.6745098 ,\n",
              "        0.63137255, 0.74117647, 0.24313725],\n",
              "       [0.        , 0.26666667, 0.36862745, 0.35294118, 0.43529412,\n",
              "        0.44705882, 0.43529412, 0.44705882, 0.45098039, 0.49803922,\n",
              "        0.52941176, 0.53333333, 0.56078431, 0.49411765, 0.49803922,\n",
              "        0.59215686, 0.60392157, 0.56078431, 0.58039216, 0.49019608,\n",
              "        0.63529412, 0.63529412, 0.56470588, 0.54117647, 0.6       ,\n",
              "        0.63529412, 0.76862745, 0.22745098],\n",
              "       [0.2745098 , 0.6627451 , 0.50588235, 0.40784314, 0.38431373,\n",
              "        0.39215686, 0.36862745, 0.38039216, 0.38431373, 0.4       ,\n",
              "        0.42352941, 0.41568627, 0.46666667, 0.47058824, 0.50588235,\n",
              "        0.58431373, 0.61176471, 0.65490196, 0.74509804, 0.74509804,\n",
              "        0.76862745, 0.77647059, 0.77647059, 0.73333333, 0.77254902,\n",
              "        0.74117647, 0.72156863, 0.14117647],\n",
              "       [0.0627451 , 0.49411765, 0.67058824, 0.7372549 , 0.7372549 ,\n",
              "        0.72156863, 0.67058824, 0.6       , 0.52941176, 0.47058824,\n",
              "        0.49411765, 0.49803922, 0.57254902, 0.7254902 , 0.76470588,\n",
              "        0.81960784, 0.81568627, 1.        , 0.81960784, 0.69411765,\n",
              "        0.96078431, 0.98823529, 0.98431373, 0.98431373, 0.96862745,\n",
              "        0.8627451 , 0.80784314, 0.19215686],\n",
              "       [0.        , 0.        , 0.        , 0.04705882, 0.2627451 ,\n",
              "        0.41568627, 0.64313725, 0.7254902 , 0.78039216, 0.82352941,\n",
              "        0.82745098, 0.82352941, 0.81568627, 0.74509804, 0.58823529,\n",
              "        0.32156863, 0.03137255, 0.        , 0.        , 0.        ,\n",
              "        0.69803922, 0.81568627, 0.7372549 , 0.68627451, 0.63529412,\n",
              "        0.61960784, 0.59215686, 0.04313725],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgKw6Bs6AqKm"
      },
      "source": [
        "NORMALIZING THE IMAGES."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0BfrkqKvNpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8507ec31-98f7-4d06-be07-b84a2f523f7f"
      },
      "source": [
        "training_images=training_images / 255.0\n",
        "training_images.shape\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pdMhd5wAksx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcYvseltAjao"
      },
      "source": [
        "Viusalizing the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKmyBLxIvNsw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0743b0c-2c99-4013-f4c0-b8e41b7a334a"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[97])\n",
        "print(training_labels[97])\n",
        "print(training_images[97])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.94901961 0.83921569 0.80392157 0.81176471 0.81176471 0.75294118\n",
            "  0.8745098  0.7372549  0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.37254902 1.         0.9254902  0.95686275 0.94901961 0.9372549  0.88627451\n",
            "  0.90980392 1.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.7254902  0.96862745 0.86666667 0.89019608 0.90196078 0.89803922 0.8745098\n",
            "  0.83921569 1.         0.30196078 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.89411765 0.95294118 0.92156863 0.92156863 0.88235294 0.90196078 0.87058824\n",
            "  0.84705882 0.98431373 0.49411765 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         1.         0.94117647 0.90196078 0.96470588 0.90196078 0.90980392 0.92941176\n",
            "  0.90588235 0.96078431 0.63921569 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.98039216 0.94901961 0.91372549 0.94117647 0.94901961 0.89411765 0.94509804\n",
            "  0.93333333 0.96470588 0.63529412 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.95294118 0.95686275 0.89803922 0.92156863 0.99607843 0.94117647 0.97254902\n",
            "  0.90980392 0.98039216 0.6        0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.91764706 0.97254902 0.87058824 0.95294118 0.89803922 0.93333333 0.99607843\n",
            "  0.91372549 1.         0.51764706 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.8745098  0.99215686 0.85098039 1.         0.52941176 0.69019608 1.\n",
            "  0.88627451 1.         0.45490196 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.81176471 0.99215686 0.89019608 1.         0.33333333 0.42745098 1.\n",
            "  0.85490196 1.         0.38431373 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.70196078 0.99215686 0.89019608 1.         0.03921569 0.27843137 1.\n",
            "  0.89019608 1.         0.2745098  0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.60784314 0.99607843 0.89803922 1.         0.         0.21960784 1.\n",
            "  0.89411765 1.         0.18039216 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.51764706 0.99607843 0.90980392 1.         0.         0.11372549 1.\n",
            "  0.90196078 1.         0.12156863 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.43529412 1.         0.92156863 1.         0.         0.1254902  1.\n",
            "  0.90980392 1.         0.06666667 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.34509804 1.         0.92941176 0.98039216 0.         0.13333333 1.\n",
            "  0.91764706 1.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.25490196 1.         0.92156863 0.97647059 0.         0.06666667 1.\n",
            "  0.9254902  1.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.24313725 0.99607843 0.92941176 0.95294118 0.         0.03529412 1.\n",
            "  0.94117647 0.99607843 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.21960784 0.99215686 0.94117647 0.91764706 0.         0.01568627 1.\n",
            "  0.95686275 0.96470588 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.19607843 0.98431373 0.94117647 0.83921569 0.         0.         1.\n",
            "  0.96470588 0.92156863 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.15294118 0.96470588 0.94117647 0.81568627 0.         0.         1.\n",
            "  0.97254902 0.8745098  0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.11372549 0.94509804 0.94901961 0.80784314 0.         0.         1.\n",
            "  0.97647059 0.82745098 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.07843137 0.9372549  0.96470588 0.71372549 0.         0.         1.\n",
            "  0.97647059 0.81568627 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02745098 0.9254902  0.98039216 0.6        0.         0.         0.96862745\n",
            "  0.98823529 0.80392157 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.90980392 0.98823529 0.46666667 0.         0.         0.8745098\n",
            "  1.         0.72941176 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.87843137 0.99607843 0.35686275 0.         0.         0.78431373\n",
            "  1.         0.70196078 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.82745098 0.99607843 0.2745098  0.         0.         0.57647059\n",
            "  1.         0.58039216 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.74509804 1.         0.13333333 0.         0.         0.46666667\n",
            "  1.         0.4627451  0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.2627451  0.48235294 0.         0.         0.         0.08627451\n",
            "  0.56862745 0.05098039 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CB3Bb4PAQTk"
      },
      "source": [
        "creating the model with using the callback to stop the training after reaching a required accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Gfgnpu2svm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3bd6f4-eb0c-40ef-9dc6-8de65cc7a55b"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if(logs.get('accuracy')> 0.9):\n",
        "      print('\\nReached the required the accuracy')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=15, callbacks=[callbacks])\n",
        "test_loss = model.evaluate(test_images, test_labels )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 7s 2ms/step - loss: 0.4957 - accuracy: 0.8256\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3753 - accuracy: 0.8644\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3382 - accuracy: 0.8772\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3150 - accuracy: 0.8845\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2983 - accuracy: 0.8916\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2829 - accuracy: 0.8956\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2699 - accuracy: 0.8991\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2588 - accuracy: 0.9046\n",
            "\n",
            "Reached the required the accuracy\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxxpJgwZ1NaK"
      },
      "source": [
        "Sequential: That defines a SEQUENCE of layers in the neural network\n",
        "\n",
        "Dense: Adds a layer of neurons\n",
        "\n",
        "Softmax takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt_AUtKjvw21",
        "outputId": "b4920693-26d1-4f21-87da-af462b4bf6cf"
      },
      "source": [
        "test_loss"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32680320739746094, 0.885200023651123]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnxDKXkcAFp0"
      },
      "source": [
        "Using the convolution layer and maxpooling to train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui2n8kSkcnEe",
        "outputId": "98a9ccf0-8f05-4db1-f670-6b9d9b2e44e9"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "\n",
        "model1= tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape = (28,28, 1)),\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape = (28,28, 1)),\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model1.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model1.fit(training_images, training_labels, epochs=25)\n",
        "test_loss1 = model1.evaluate(test_images, test_labels )\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 23s 6ms/step - loss: 0.4356 - accuracy: 0.8411\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2936 - accuracy: 0.8913\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2476 - accuracy: 0.9083\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2142 - accuracy: 0.9200\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1871 - accuracy: 0.9292\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1643 - accuracy: 0.9384\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1448 - accuracy: 0.9455\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1269 - accuracy: 0.9512\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1127 - accuracy: 0.9578\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0979 - accuracy: 0.9625\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0847 - accuracy: 0.9681\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0764 - accuracy: 0.9714\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0664 - accuracy: 0.9739\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0611 - accuracy: 0.9772\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0543 - accuracy: 0.9795\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0479 - accuracy: 0.9823\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0468 - accuracy: 0.9821\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0404 - accuracy: 0.9847\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0377 - accuracy: 0.9862\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0360 - accuracy: 0.9868\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0321 - accuracy: 0.9888\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0324 - accuracy: 0.9885\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0285 - accuracy: 0.9898\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0276 - accuracy: 0.9904\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0263 - accuracy: 0.9902\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5994 - accuracy: 0.9104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqLPFiyO2AcM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3vMEM1u2B6t",
        "outputId": "1688f82e-57c6-4d17-d2a3-fd780944ad40"
      },
      "source": [
        "test_loss1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5993992686271667, 0.9103999733924866]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}